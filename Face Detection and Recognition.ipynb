{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection and Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T02:57:09.176017Z",
     "start_time": "2022-05-24T02:57:09.166040Z"
    }
   },
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T01:16:46.243054Z",
     "start_time": "2022-05-24T01:16:45.862882Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T01:16:46.943721Z",
     "start_time": "2022-05-24T01:16:46.890983Z"
    }
   },
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting faces for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T01:16:47.819483Z",
     "start_time": "2022-05-24T01:16:47.811500Z"
    }
   },
   "outputs": [],
   "source": [
    "def face_extractor(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "    \n",
    "    return cropped_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T01:03:17.149524Z",
     "start_time": "2022-05-23T01:03:02.547546Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        face = face_extractor(frame)\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        filename = \"faces/user\"+str(count)+\".jpg\"\n",
    "        cv2.imwrite(filename, face)\n",
    "        count+=1\n",
    "        cv2.putText(face, str(count), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, color = (0,0,255), thickness= 2)\n",
    "        cv2.imshow(\"Face\", face)\n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "    if cv2.waitKey(1)==13 or count==200:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T01:16:51.490433Z",
     "start_time": "2022-05-24T01:16:51.466497Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['faces/user0.jpg',\n",
       " 'faces/user1.jpg',\n",
       " 'faces/user10.jpg',\n",
       " 'faces/user100.jpg',\n",
       " 'faces/user101.jpg',\n",
       " 'faces/user102.jpg',\n",
       " 'faces/user103.jpg',\n",
       " 'faces/user104.jpg',\n",
       " 'faces/user105.jpg',\n",
       " 'faces/user106.jpg',\n",
       " 'faces/user107.jpg',\n",
       " 'faces/user108.jpg',\n",
       " 'faces/user109.jpg',\n",
       " 'faces/user11.jpg',\n",
       " 'faces/user110.jpg',\n",
       " 'faces/user111.jpg',\n",
       " 'faces/user112.jpg',\n",
       " 'faces/user113.jpg',\n",
       " 'faces/user114.jpg',\n",
       " 'faces/user115.jpg',\n",
       " 'faces/user116.jpg',\n",
       " 'faces/user117.jpg',\n",
       " 'faces/user118.jpg',\n",
       " 'faces/user119.jpg',\n",
       " 'faces/user12.jpg',\n",
       " 'faces/user120.jpg',\n",
       " 'faces/user121.jpg',\n",
       " 'faces/user122.jpg',\n",
       " 'faces/user123.jpg',\n",
       " 'faces/user124.jpg',\n",
       " 'faces/user125.jpg',\n",
       " 'faces/user126.jpg',\n",
       " 'faces/user127.jpg',\n",
       " 'faces/user128.jpg',\n",
       " 'faces/user129.jpg',\n",
       " 'faces/user13.jpg',\n",
       " 'faces/user130.jpg',\n",
       " 'faces/user131.jpg',\n",
       " 'faces/user132.jpg',\n",
       " 'faces/user133.jpg',\n",
       " 'faces/user134.jpg',\n",
       " 'faces/user135.jpg',\n",
       " 'faces/user136.jpg',\n",
       " 'faces/user137.jpg',\n",
       " 'faces/user138.jpg',\n",
       " 'faces/user139.jpg',\n",
       " 'faces/user14.jpg',\n",
       " 'faces/user140.jpg',\n",
       " 'faces/user141.jpg',\n",
       " 'faces/user142.jpg',\n",
       " 'faces/user143.jpg',\n",
       " 'faces/user144.jpg',\n",
       " 'faces/user145.jpg',\n",
       " 'faces/user146.jpg',\n",
       " 'faces/user147.jpg',\n",
       " 'faces/user148.jpg',\n",
       " 'faces/user149.jpg',\n",
       " 'faces/user15.jpg',\n",
       " 'faces/user150.jpg',\n",
       " 'faces/user151.jpg',\n",
       " 'faces/user152.jpg',\n",
       " 'faces/user153.jpg',\n",
       " 'faces/user154.jpg',\n",
       " 'faces/user155.jpg',\n",
       " 'faces/user156.jpg',\n",
       " 'faces/user157.jpg',\n",
       " 'faces/user158.jpg',\n",
       " 'faces/user159.jpg',\n",
       " 'faces/user16.jpg',\n",
       " 'faces/user160.jpg',\n",
       " 'faces/user161.jpg',\n",
       " 'faces/user162.jpg',\n",
       " 'faces/user163.jpg',\n",
       " 'faces/user164.jpg',\n",
       " 'faces/user165.jpg',\n",
       " 'faces/user166.jpg',\n",
       " 'faces/user167.jpg',\n",
       " 'faces/user168.jpg',\n",
       " 'faces/user169.jpg',\n",
       " 'faces/user17.jpg',\n",
       " 'faces/user170.jpg',\n",
       " 'faces/user171.jpg',\n",
       " 'faces/user172.jpg',\n",
       " 'faces/user173.jpg',\n",
       " 'faces/user174.jpg',\n",
       " 'faces/user175.jpg',\n",
       " 'faces/user176.jpg',\n",
       " 'faces/user177.jpg',\n",
       " 'faces/user178.jpg',\n",
       " 'faces/user179.jpg',\n",
       " 'faces/user18.jpg',\n",
       " 'faces/user180.jpg',\n",
       " 'faces/user181.jpg',\n",
       " 'faces/user182.jpg',\n",
       " 'faces/user183.jpg',\n",
       " 'faces/user184.jpg',\n",
       " 'faces/user185.jpg',\n",
       " 'faces/user186.jpg',\n",
       " 'faces/user187.jpg',\n",
       " 'faces/user188.jpg',\n",
       " 'faces/user189.jpg',\n",
       " 'faces/user19.jpg',\n",
       " 'faces/user190.jpg',\n",
       " 'faces/user191.jpg',\n",
       " 'faces/user192.jpg',\n",
       " 'faces/user193.jpg',\n",
       " 'faces/user194.jpg',\n",
       " 'faces/user195.jpg',\n",
       " 'faces/user196.jpg',\n",
       " 'faces/user197.jpg',\n",
       " 'faces/user198.jpg',\n",
       " 'faces/user199.jpg',\n",
       " 'faces/user2.jpg',\n",
       " 'faces/user20.jpg',\n",
       " 'faces/user21.jpg',\n",
       " 'faces/user22.jpg',\n",
       " 'faces/user23.jpg',\n",
       " 'faces/user24.jpg',\n",
       " 'faces/user25.jpg',\n",
       " 'faces/user26.jpg',\n",
       " 'faces/user27.jpg',\n",
       " 'faces/user28.jpg',\n",
       " 'faces/user29.jpg',\n",
       " 'faces/user3.jpg',\n",
       " 'faces/user30.jpg',\n",
       " 'faces/user31.jpg',\n",
       " 'faces/user32.jpg',\n",
       " 'faces/user33.jpg',\n",
       " 'faces/user34.jpg',\n",
       " 'faces/user35.jpg',\n",
       " 'faces/user36.jpg',\n",
       " 'faces/user37.jpg',\n",
       " 'faces/user38.jpg',\n",
       " 'faces/user39.jpg',\n",
       " 'faces/user4.jpg',\n",
       " 'faces/user40.jpg',\n",
       " 'faces/user41.jpg',\n",
       " 'faces/user42.jpg',\n",
       " 'faces/user43.jpg',\n",
       " 'faces/user44.jpg',\n",
       " 'faces/user45.jpg',\n",
       " 'faces/user46.jpg',\n",
       " 'faces/user47.jpg',\n",
       " 'faces/user48.jpg',\n",
       " 'faces/user49.jpg',\n",
       " 'faces/user5.jpg',\n",
       " 'faces/user50.jpg',\n",
       " 'faces/user51.jpg',\n",
       " 'faces/user52.jpg',\n",
       " 'faces/user53.jpg',\n",
       " 'faces/user54.jpg',\n",
       " 'faces/user55.jpg',\n",
       " 'faces/user56.jpg',\n",
       " 'faces/user57.jpg',\n",
       " 'faces/user58.jpg',\n",
       " 'faces/user59.jpg',\n",
       " 'faces/user6.jpg',\n",
       " 'faces/user60.jpg',\n",
       " 'faces/user61.jpg',\n",
       " 'faces/user62.jpg',\n",
       " 'faces/user63.jpg',\n",
       " 'faces/user64.jpg',\n",
       " 'faces/user65.jpg',\n",
       " 'faces/user66.jpg',\n",
       " 'faces/user67.jpg',\n",
       " 'faces/user68.jpg',\n",
       " 'faces/user69.jpg',\n",
       " 'faces/user7.jpg',\n",
       " 'faces/user70.jpg',\n",
       " 'faces/user71.jpg',\n",
       " 'faces/user72.jpg',\n",
       " 'faces/user73.jpg',\n",
       " 'faces/user74.jpg',\n",
       " 'faces/user75.jpg',\n",
       " 'faces/user76.jpg',\n",
       " 'faces/user77.jpg',\n",
       " 'faces/user78.jpg',\n",
       " 'faces/user79.jpg',\n",
       " 'faces/user8.jpg',\n",
       " 'faces/user80.jpg',\n",
       " 'faces/user81.jpg',\n",
       " 'faces/user82.jpg',\n",
       " 'faces/user83.jpg',\n",
       " 'faces/user84.jpg',\n",
       " 'faces/user85.jpg',\n",
       " 'faces/user86.jpg',\n",
       " 'faces/user87.jpg',\n",
       " 'faces/user88.jpg',\n",
       " 'faces/user89.jpg',\n",
       " 'faces/user9.jpg',\n",
       " 'faces/user90.jpg',\n",
       " 'faces/user91.jpg',\n",
       " 'faces/user92.jpg',\n",
       " 'faces/user93.jpg',\n",
       " 'faces/user94.jpg',\n",
       " 'faces/user95.jpg',\n",
       " 'faces/user96.jpg',\n",
       " 'faces/user97.jpg',\n",
       " 'faces/user98.jpg',\n",
       " 'faces/user99.jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = [\"faces/\"+str(i) for i in listdir(\"faces\")]\n",
    "filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training Data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T01:16:55.800957Z",
     "start_time": "2022-05-24T01:16:55.579216Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train = [],[]\n",
    "for i, file in enumerate(filepath):\n",
    "    image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    x_train.append(np.asarray(image, dtype = np.uint8))\n",
    "    y_train.append(np.asarray(1, dtype = np.uint8))\n",
    "\n",
    "y_train = np.array(y_train, dtype = np.int32)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T01:16:59.769390Z",
     "start_time": "2022-05-24T01:16:59.162060Z"
    }
   },
   "outputs": [],
   "source": [
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.train(x_train, y_train)\n",
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face detection and recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T02:34:22.916240Z",
     "start_time": "2022-05-24T02:34:22.896294Z"
    }
   },
   "outputs": [],
   "source": [
    "def face_detector(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,)\n",
    "    if faces is ():\n",
    "        return image, []\n",
    "    for  (x,y,w,h) in faces:\n",
    "        cv2.rectangle(image,pt1 = (x,y), pt2 = (x+w, y+h),color = (0,255,255), thickness = 2)\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200,200))\n",
    "    \n",
    "    return image, roi    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T02:55:04.721615Z",
     "start_time": "2022-05-24T02:39:55.416720Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    image, face = face_detector(frame)\n",
    "    try:\n",
    "        gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        result = model.predict(gray)\n",
    "        if result[1]<500:\n",
    "            confidence = int(100 * (1 - (result[1]) / 300))\n",
    "        \n",
    "        cv2.putText(image,(\"Confidence Level:\" + str(confidence)+\"%\"), (50,50), \n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1, color = (255,0,0), thickness= 2)\n",
    "        \n",
    "        \n",
    "        if confidence > 75:\n",
    "            cv2.putText(image, \"Unlocked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 55, 255), 2)\n",
    "            cv2.imshow('FACE DETECTOR', image)\n",
    "        else:\n",
    "            cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 55, 0), 2)\n",
    "            cv2.imshow('FACE DETECTOR', image)\n",
    "        \n",
    "    except:\n",
    "        cv2.putText(image, \"Face Not Detected\", (100,100), cv2.FONT_HERSHEY_COMPLEX,1,\n",
    "                   color = (0,255,0), thickness = 2)\n",
    "        cv2.imshow(\"FACE DETECTOR\", image)\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
